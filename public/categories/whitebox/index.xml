<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>whitebox on IvoBeerens.NL | All about End User Computing, AVD, W365 and Infrastructure as Code (IaC)</title><link>/categories/whitebox/</link><description>Recent content in whitebox on IvoBeerens.NL | All about End User Computing, AVD, W365 and Infrastructure as Code (IaC)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 24 Feb 2024 09:43:55 +0100</lastBuildDate><atom:link href="/categories/whitebox/index.xml" rel="self" type="application/rss+xml"/><item><title>New whitebox for extending my home lab</title><link>/2015/01/05/new-whitebox-extending-home-lab/</link><pubDate>Mon, 05 Jan 2015 11:48:08 +0000</pubDate><guid>/2015/01/05/new-whitebox-extending-home-lab/</guid><description>For a couple of months I’m searching for an extra whitebox host for extending my home lab environment. My current lab whitebox is a Haswell based whitebox (see: link). Here is an overview of the new lab environment:
For the new whitebox I had the following requirements:
Hardware such as NICs must be recognized by VMware ESXi Use 32 GB memory or more Low power consumption Expandable Small form factor Quiet Possibility to run nested hypervisors such as VMware ESXi and Hyper-V Remote Management Possibility to create a VMware Cluster and use vMotion, HA, DRS and DPM with the existing Haswell host I reviewed the following popular home lab systems:</description></item><item><title>Haswell low power whitebox for ESXi and Hyper-V</title><link>/2013/06/25/haswell-low-power-whitebox-for-esxi-and-hyper-v/</link><pubDate>Tue, 25 Jun 2013 16:12:29 +0000</pubDate><guid>/2013/06/25/haswell-low-power-whitebox-for-esxi-and-hyper-v/</guid><description>I was searching for a new whitebox for my home lab. I had the following requirements for the new whitebox:
Low power consumption for 24x7 running &amp;gt;16 GB memory Expansion slots for PCI(-E) cards Good performance Low noise A couple of weeks ago Intel released the new 4th generation Haswell CPUs that consumes less power. Seems to be interesting option for building a low power consumption whitebox. So I did some research and ordered the following hardware components:</description></item><item><title>Enable the Intel I217-V NIC in Windows Server 2012</title><link>/2013/06/24/enable-the-intel-i217-v-nic-in-windows-server-2012/</link><pubDate>Mon, 24 Jun 2013 20:44:10 +0000</pubDate><guid>/2013/06/24/enable-the-intel-i217-v-nic-in-windows-server-2012/</guid><description>My new Gigabyte Z87-D3HP motherboard with support for 4th Generation Intel® Core™ processors (codename Haswell) has a onboard Intel I217-V NIC. The NIC is not recognized and supported in Windows Server 2012. As with the “Enable the Intel 82579V NIC in Windows Server 2012 ” blogpost it is possible to enable the NIC in Windows Server 2012. Here are the steps:
To be able to modify the drivers you need to run the the following commands: bcdedit -set loadoptions DISABLE_INTEGRITY_CHECKS bcdedit -set TESTSIGNING ON Reboot the system</description></item><item><title>Control (remotely) the power of your Home Lab</title><link>/2013/02/15/control-remotely-the-power-of-your-home-lab/</link><pubDate>Fri, 15 Feb 2013 12:39:15 +0000</pubDate><guid>/2013/02/15/control-remotely-the-power-of-your-home-lab/</guid><description>I have a lab at home to test for example VMware vSphere and Microsoft stuff. Running your home lab for 24/7 will result in a high electricity bill. For a couple of months I use the Internet Control Station ICS-1000 (ICS-1000) to power on my home lab when needed from anywhere. The ICS-1000 controls (left picture) controls the receivers (right picture). The ICS-1000 is connected to my router. In the receivers are the power cables plugged from the devices you manage.</description></item><item><title>Intel X79 whitebox for vSphere 5 and Hyper-V 3</title><link>/2012/03/13/intel-x79-whitebox-for-vsphere-5-and-hyper-v-3/</link><pubDate>Tue, 13 Mar 2012 11:53:56 +0000</pubDate><guid>/2012/03/13/intel-x79-whitebox-for-vsphere-5-and-hyper-v-3/</guid><description>In an earlier blog post (found here ) I mentioned that it is time for a new homebrew whitebox based on the Intel X79 chipset. With the X79 chipset it is possible to install 64GB of memory (8 x 8 GB). Because the 8 GB DIMMs are expensive on the moment, I decided to use 8 x 4GB DIMMs (total 32GB).
I decided to create one physical host for testing VMware vSphere 5, vCloud Director, VMware SRM, VMware View 5 etc.</description></item><item><title>VMware ESXi 5 whitebox NIC support</title><link>/2011/12/13/vmware-esxi-5-whitebox-nic-support/</link><pubDate>Tue, 13 Dec 2011 15:44:34 +0000</pubDate><guid>/2011/12/13/vmware-esxi-5-whitebox-nic-support/</guid><description>I tested the NICs below in my VMware ESXi 5.x whitebox server at home. Here the status:
NICRecognized by VMware ESXi 5Listed in ESXi 5 asIntel PRO/1000GT Desktop Adapter PCIYesIntel 82541PI Gigabit Ethernet ControllerRealtek RTL 8111EYesRealtek 8168 Gigabit EthernetIntel Gigabit CT Desktop Adapter PCI-eYesIntel Corporation 82574LIntel 82579 Gigabit LAN controllerNo You need the make a customized ESXi 5 ISO or VIB file.This is a not supported configuration!Intel Corporation 82579V&amp;nbsp;orIntel Corporation 82579LMTo add for example the Intel 82579 chipset, create a customized ESXi 5 ISO.</description></item><item><title>Time for new whitebox for your VMware vSphere or MS Hyper-V home lab environment?</title><link>/2011/11/18/time-for-new-whitebox-for-your-vmware-vsphere-or-ms-hyper-v-home-lab-environment/</link><pubDate>Fri, 18 Nov 2011 10:27:43 +0000</pubDate><guid>/2011/11/18/time-for-new-whitebox-for-your-vmware-vsphere-or-ms-hyper-v-home-lab-environment/</guid><description>When using a whitebox lab environment at home and like to test for example vSphere 5, vCloud Director, VMware View and MS Hyper-V (nested in VMware vSphere you need a lot of processor power and memory. In almost all whitebox lab environment the processor power is not the problem but the amount of memory is.
Till now the Sandy Bridge desktop boards support up to 32GB memory with only four DIMM slots on the motherboard.</description></item><item><title>VMware ESXi 5 whitebox supported motherboard</title><link>/2011/09/01/vmware-esxi-5-whitebox-supported-motherboard/</link><pubDate>Thu, 01 Sep 2011 14:05:50 +0000</pubDate><guid>/2011/09/01/vmware-esxi-5-whitebox-supported-motherboard/</guid><description>If you want a low power consumption whitebox motherboard to run some VMs that are not resource intensive the Asus E35M1-M PRO Zacate motherboard is an option. It has an AMD E-350 dual core 1,6 GHz processor with passive cooling, onboard graphics, max 8GB memory support, onboard LAN and 5x SATA 6 onboard. And it’s cheap.
I test the Asus E35M1-M PRO Zacate motherboard in my home lab, and it will run for VMware ESXi 5.</description></item></channel></rss>