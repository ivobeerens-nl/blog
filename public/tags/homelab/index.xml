<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>homelab on IvoBeerens.NL | All about End User Computing, AVD, W365 and Infrastructure as Code (IaC)</title><link>/tags/homelab/</link><description>Recent content in homelab on IvoBeerens.NL | All about End User Computing, AVD, W365 and Infrastructure as Code (IaC)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 24 Feb 2024 13:23:24 +0100</lastBuildDate><atom:link href="/tags/homelab/index.xml" rel="self" type="application/rss+xml"/><item><title>NVMe SSDs are not recognized anymore after upgrading to VMware ESXi 7</title><link>/2020/04/09/nvme-ssds-are-not-recognized-anymore-after-upgrading-to-vmware-esxi-7/</link><pubDate>Thu, 09 Apr 2020 09:47:19 +0000</pubDate><guid>/2020/04/09/nvme-ssds-are-not-recognized-anymore-after-upgrading-to-vmware-esxi-7/</guid><description>Last week VMware released vSphere 7. The first thing I did was upgrading my homelab. My homelab has two hosts (Shuttle SH370R6 Plus and a Shuttle SH370R8 Plus). After upgrading my hosts from VMware ESXi 6.7 Update 3 to VMware ESXi 7, the NVMe SSDs are not recognized anymore. I Have the following NVMe SSD disks in the hosts:</description></item><item><title>VMware homelab build of materials and configuration</title><link>/2020/02/07/vmware-homelab-build-of-materials-and-configuration/</link><pubDate>Fri, 07 Feb 2020 09:39:40 +0000</pubDate><guid>/2020/02/07/vmware-homelab-build-of-materials-and-configuration/</guid><description>William Lam has started a great initiative. William asked (link ) everyone who owns a homelab to share there build of materials (BOM) and configuration so the vCommunity can benefit and learn from. I have a simple homelab configuration, the materials I used and configuration are listed below:
Internet
Cable modem in bridge mode with 250 Mbit/s down and 25 Mbit/s upload.</description></item><item><title>Using the new Shuttle SH370R8 as home lab server with VMware ESXi</title><link>/2019/06/04/using-the-shuttle-sh370r8-as-home-lab-server-with-vmware-esxi/</link><pubDate>Tue, 04 Jun 2019 11:04:42 +0000</pubDate><guid>/2019/06/04/using-the-shuttle-sh370r8-as-home-lab-server-with-vmware-esxi/</guid><description>In January 2019 I did a review of the Shuttle SH370R6 (link ) using VMware ESXi. A couple of weeks ago the new Shuttle SH370R8 is released. The main differences between the Shuttle SH370R6 and SH370R8 are:
Update October 19, 2020: Supports up to 128 GB of RAM! Memory compatibility list: link Ready for the 8th/9th Gen Intel Coffee Lake processors Dual Intel Gigabit Ethernet An extra fan in front of the chassis for a better airflow Front panel (Microphone input (3.</description></item><item><title>DHCP problems after Ubiquiti EdgeRouter firmware upgrade</title><link>/2018/04/16/dhcp-problems-after-ubiquiti-edgerouter-firmware-upgrade/</link><pubDate>Mon, 16 Apr 2018 06:57:40 +0000</pubDate><guid>/2018/04/16/dhcp-problems-after-ubiquiti-edgerouter-firmware-upgrade/</guid><description>In my homelab I use a Ubiquiti EdgeRouter Lite 3-port and UniFi AC Access Points for some time now. After upgrading the Ubiquiti EdgeRouter to the latest firmware (EdgeOS 1.10.1) my WIFI devices where unable to get an IP address. I have different VLANs defined on the EdgeRouter for the WIFI networks.</description></item><item><title>Home lab extension with an Intel NUC 6th generation</title><link>/2016/02/24/intel-nuc-6th-generation-as-home-server/</link><pubDate>Wed, 24 Feb 2016 19:37:32 +0000</pubDate><guid>/2016/02/24/intel-nuc-6th-generation-as-home-server/</guid><description>For my home lab I bought a 6th generation Intel NUC. The Intel NUC has following specifications:
Intel NUC6i3SYH Intel i3-6100u (Skylake) 2.3 GHz Dual Core, 3 MB cache, 15W TDP 2 memory slots for DDR4-2133 SODIMM memory, maximum is 32 GB memory Intel HD Graphics 520 GPU Intel I219-V GigabitÂ network adapter and Intel Wireless-AC 8260 WIFI adapter Option to install a 2.</description></item><item><title>Home lab extension with a Samsung 950 PRO M.2 SSD</title><link>/2015/12/14/4131/</link><pubDate>Mon, 14 Dec 2015 19:56:08 +0000</pubDate><guid>/2015/12/14/4131/</guid><description>Last month I extended my VMware ESXi and Hyper-V home lab with a Samsung 950 Pro SSD. The Samsung 950 Pro SSD is the next-gen SSD that has the following characteristics:
Uses V-NAND memory and the Non-Volatile Memory Express (NVME) protocol. This takes away the 600 MBps bandwidth limit with the SATA protocol.</description></item><item><title>Intel X79 whitebox for vSphere 5 and Hyper-V 3</title><link>/2012/03/13/intel-x79-whitebox-for-vsphere-5-and-hyper-v-3/</link><pubDate>Tue, 13 Mar 2012 11:53:56 +0000</pubDate><guid>/2012/03/13/intel-x79-whitebox-for-vsphere-5-and-hyper-v-3/</guid><description>In an earlier blog post (found here ) I mentioned that it is time for a new homebrew whitebox based on the Intel X79 chipset. With the X79 chipset it is possible to install 64GB of memory (8 x 8 GB). Because the 8 GB DIMMs are expensive on the moment, I decided to use 8 x 4GB DIMMs (total 32GB).</description></item><item><title>Time for new whitebox for your VMware vSphere or MS Hyper-V home lab environment?</title><link>/2011/11/18/time-for-new-whitebox-for-your-vmware-vsphere-or-ms-hyper-v-home-lab-environment/</link><pubDate>Fri, 18 Nov 2011 10:27:43 +0000</pubDate><guid>/2011/11/18/time-for-new-whitebox-for-your-vmware-vsphere-or-ms-hyper-v-home-lab-environment/</guid><description>When using a whitebox lab environment at home and like to test for example vSphere 5, vCloud Director, VMware View and MS Hyper-V (nested in VMware vSphere you need a lot of processor power and memory. In almost all whitebox lab environment the processor power is not the problem but the amount of memory is.</description></item><item><title>VMware ESXi 5 whitebox supported motherboard</title><link>/2011/09/01/vmware-esxi-5-whitebox-supported-motherboard/</link><pubDate>Thu, 01 Sep 2011 14:05:50 +0000</pubDate><guid>/2011/09/01/vmware-esxi-5-whitebox-supported-motherboard/</guid><description>If you want a low power consumption whitebox motherboard to run some VMs that are not resource intensive the Asus E35M1-M PRO Zacate motherboard is an option. It has an AMD E-350 dual core 1,6 GHz processor with passive cooling, onboard graphics, max 8GB memory support, onboard LAN and 5x SATA 6 onboard.</description></item><item><title>Homebrew / Whitelist Hyper-V R2 home server NAS</title><link>/2011/03/18/homebrew-whitelist-hyper-v-home-server-nas/</link><pubDate>Fri, 18 Mar 2011 10:30:46 +0000</pubDate><guid>/2011/03/18/homebrew-whitelist-hyper-v-home-server-nas/</guid><description>For my home lab i was looking for a home server with NAS functionality. My current Iomega IX2 (2x500GB) NAS is replaced by this server. For this server I had the following requirements
Low power consumption (24x7) Low noise Flexibly and room to expand with extra hard drive(s),hardware RAID and a NIC Home server functionality for sharing photos, music, documents and films NAS functionality with iSCSI and NFS protocol FTP server Hypervisor enabled Backup server Print server Active Directory DNS server Download server Wake-on-LAN functionality to start other virtualization hosts I selected the following components:</description></item><item><title>New VMware ESX whitebox</title><link>/2008/12/12/new-VMware-esx-whitebox/</link><pubDate>Fri, 12 Dec 2008 21:08:52 +0000</pubDate><guid>/2008/12/12/new-VMware-esx-whitebox/</guid><description>A couple of weeks ago my desktop PC died, so my girlfriend could not read there e-mail. I decide to turn my OLD VMware ESX test server into a Microsoft Vista workstation and buy a new whitebox. After searching the internet and comparing components, I found the following configuration:
CoolerMaster Centurion 590 mini tower CoolerMaster Real Power 520W modular Power supply Asus P5BP-E/4L (with 4 onboard NICS) Intel Core 2 Quad 6600 Processor Boxed Kingston 8GB 800MHz DDR2 memory Samsung Spinpoint F1 1TB I had already a LSI Megaraid SATA-4 RAID controller.</description></item></channel></rss>